# Integration of Imagine Processing and our RobotArm

## Screenshots (Inputs)

There is a script to automactically catch the screenshots from conveyor belt.
The screenshots we got could be used as inputs imagine data for our image processing.

## UI (Outputs)

From the results from our image processing, we can give the feedback to our Unity RobotArm.
Hence, we made a user interface to control the results.


## Image Processing

Through our plenty of input screenshots, we were using image processing to get the order we want. Then transform these results to our control panal to have the correct orders. So our RobotArm have the ability to detect objects and grab items that we want.


## Demo

## Final Presentation

1.Debugs (Unity or Python codes)
2.VoTT (Annotate images and export the annotations)